data_configs:
  lang_pair: "en-de"
  train_data:
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/train.src.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/train.mt.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/train.pos.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data/train.len"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data/train.lenpe"
  valid_data:
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/dev.src.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/dev.mt.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/dev.pos.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data/dev.len"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data/dev.lenpe"
  test_data:
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/test.src.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/test.mt.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data_bpe/test.pos.BPE"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data/test.len"
    - "/home/user_data_182b/yanym/qe/data/wmt19_ende/qe_data/test.lenpe"
  vocabularies:
    - type: "bpe"
      dict_path: "/home/user_data_182b/yanym/qe/data/wmt19_ende/vocab.en.json"
      max_n_words: -1
    - type: "bpe"
      dict_path: "/home/user_data_182b/yanym/qe/data/wmt19_ende/vocab.de.json"
      max_n_words: -1
    - type: "bpe"
      dict_path: "/home/user_data_182b/yanym/qe/data/wmt19_ende/vocab.pos.json"
      max_n_words: -1
  max_len:
    - -1
    - -1
  num_refs: 1
  eval_at_char_level: false

discriminator_configs:
  model: Discriminator
  n_layers: 6
  n_head: 8
  n_labels: 3
  d_word_vec: 512
  d_model: 512
  d_inner_hid: 2048
  dropout: 0.1
  proj_share_weight: false
  label_smoothing: 0.0

optimizer_configs:
  optimizer: "adam"
  learning_rate: 0.0001
  weight_decay: 0
  grad_clip: 1.0
  optimizer_params: ~
  schedule_method: ~
  scheduler_configs:
    d_model: 512
    warmup_steps: 100

training_configs:
  seed: 1234
  max_epochs: 200
  shuffle: false
  use_bucket: false
  buffer_size: 1000
  batch_size: 1
  batching_key: "samples"
  update_cycle: 30
  valid_batch_size: 1
  disp_freq: 60
  save_freq: 1200
  num_kept_checkpoints: 1
  loss_valid_freq: 1200
  early_stop_patience: 10
